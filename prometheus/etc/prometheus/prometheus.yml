# Global config
global:
  scrape_interval: 5s
  evaluation_interval: 5s  
  scrape_timeout: 5s 
# A scrape configuration containing exactly one endpoint to scrape:# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'prometheus'
    # metrics_path defaults to '/metrics'
    # scheme defaults to 'http'.
    static_configs:
            - targets: ['localhost:9090','cadvisor:8081']
  - job_name: 'node-exporter'
    static_configs:
    - targets: ['ice-station-quellette.icestation.is:9100']
    - targets: ['swarm-queen.icestation.is:9100']
    - targets: ['swarm-worker-001.icestation.is:9100']
    - targets: ['swarm-worker-002.icestation.is:9100']
    - targets: ['pihole2.icestation.is:9100']  
  - job_name: 'rpi-exporter'
    static_configs:
    - targets: ['swarm-queen.icestation.is:9243']
    - targets: ['swarm-worker-001.icestation.is:9243']
    - targets: ['swarm-worker-002.icestation.is:9243']
    - targets: ['pihole2.icestation.is:9243']
  - job_name: 'wmi-exporter'
    static_configs:
    - targets: ['ice-station-jupiter.icestation.is:9182']
  - job_name: 'ohmgraphite'
    static_configs:
    - targets: ['ice-station-jupiter.icestation.is:4445']
# scrape kasa devices
  - job_name: 'kasa'
    static_configs:
    - targets:
      # IP of your smart plugs
      - 192.168.7.126
      - 192.168.7.127
      - 192.168.7.128
      - 192.168.7.193
      - 192.168.7.163
      - 192.168.7.175
    metrics_path: /scrape
    relabel_configs:
      - source_labels : [__address__]
        target_label: __param_target
      - source_labels: [__param_target]
        target_label: instance
      - target_label: __address__
        # IP of the exporter
        replacement: 192.168.7.5:9233
# scrape kasa_exporter itself
  - job_name: 'kasa_exporter'
    static_configs:
      - targets:
          # IP of the exporter
              - 192.168.7.5:9233
